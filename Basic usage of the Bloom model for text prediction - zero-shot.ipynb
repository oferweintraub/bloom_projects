{"cells":[{"cell_type":"markdown","metadata":{"id":"FVsKssx5ehSk"},"source":["#### Basic usage of the Bloom model for text prediction - zero-shot"]},{"cell_type":"markdown","metadata":{"id":"_yDn44M5z7DW"},"source":["##### Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IX0evvLRz-bV"},"outputs":[],"source":["# Bloom is part of the transformers library --> install it\n","!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N9Kxd6vs0EuQ"},"outputs":[],"source":["# imports needed libraries\n","import torch\n","from transformers import AutoTokenizer,AutoModelForCausalLM # A general model for casual inferencing"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ScLR6h_mlmkU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664087724663,"user_tz":-180,"elapsed":318,"user":{"displayName":"Ofer Weintraub","userId":"09168344911438364999"}},"outputId":"dc7b224f-3131-45ce-a0d8-f572267723eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Sep 25 06:35:21 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]},{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":3}],"source":["# test GPU avialiablity - otherwise cpu\n","\n","!nvidia-smi\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1664087724664,"user":{"displayName":"Ofer Weintraub","userId":"09168344911438364999"},"user_tz":-180},"id":"DQx-ocz-Fhb3"},"outputs":[],"source":["# if we have gpu bind all tensors to gpu, otherwise by default cpu\n","\n","if 'cuda' in str(device):\n","  torch.set_default_tensor_type(torch.cuda.FloatTensor) # this will allocate all tensors  on cuda\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OhdvTf0-0e2c"},"outputs":[],"source":["# define the tokenizer and model \n","\n","tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-3b\")\n","\n","model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-3b\") # here we use bloom 3b parameters"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":314,"status":"ok","timestamp":1664088226085,"user":{"displayName":"Ofer Weintraub","userId":"09168344911438364999"},"user_tz":-180},"id":"QvktgTFI6_pQ"},"outputs":[],"source":["# define any text prompt / or a list of prompts \n","# in this example we have text continuation task as well as general knowledge question/answering task mixed together\n","text_prompt = [\"Albert Einstein won a Nobel prize for\", \"Who was Otto Warburg?\" ]# ANyone can change this part"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":332,"status":"ok","timestamp":1664088228036,"user":{"displayName":"Ofer Weintraub","userId":"09168344911438364999"},"user_tz":-180},"id":"su4bjRWb7Nku","outputId":"ae12e827-b5bf-4827-a56e-cada06832b63"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Albert', 'ĠEinstein', 'Ġwon', 'Ġa', 'ĠNobel', 'Ġprize', 'Ġfor', 'Who', 'Ġwas', 'ĠOtto', 'ĠWar', 'burg', '?']\n"]}],"source":["# let's look at how bloom tokenizes text\n","tokens = tokenizer.tokenize(text_prompt)\n","print(tokens)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":332,"status":"ok","timestamp":1664088230032,"user":{"displayName":"Ofer Weintraub","userId":"09168344911438364999"},"user_tz":-180},"id":"Q2hBSZ3T7VmP","outputId":"fccbc59a-98f8-47b1-d0b7-68e9c51fc0d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[124190,  78426,  15974,    267,  41530, 127901,    613],\n","        [     3,  57647,   1620,  96624,  18692,  19616,     34]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n","        [0, 1, 1, 1, 1, 1, 1]])}"]},"metadata":{},"execution_count":18}],"source":["# convert tokens to inpt ids and return pytorch tensors\n","input_ids = tokenizer (text_prompt, return_tensors=\"pt\", padding=True)\n","input_ids"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":1361,"status":"ok","timestamp":1664088234751,"user":{"displayName":"Ofer Weintraub","userId":"09168344911438364999"},"user_tz":-180},"id":"c9R3SaTwrzio"},"outputs":[],"source":["# generate tokens as ids and review the generated ids\n","gen_text = model.generate(**input_ids, min_length=20, max_length=40, temperature=0.2)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":298,"status":"ok","timestamp":1664088237382,"user":{"displayName":"Ofer Weintraub","userId":"09168344911438364999"},"user_tz":-180},"id":"ea66OzVSvguQ"},"outputs":[],"source":["# predict possible continuation for the provided prompts\n","\n","predictions = []\n","for index, _ in enumerate(gen_text):\n","  predicted_text = tokenizer.decode(gen_text[index])\n","  # print(f\"Paragraph {index} is: {predicted_text}\\n\")\n","  predictions.append(predicted_text)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1664088249133,"user":{"displayName":"Ofer Weintraub","userId":"09168344911438364999"},"user_tz":-180},"id":"dsyRDtXeweVC","outputId":"aab7d66d-69f5-4cca-e97b-a9156aee7d4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Paragraph 0: Albert Einstein won a Nobel prize for his work on the theory of relativity. He was the first person to use the word “relativity” in his Nobel lecture.\n","\n","Paragraph 1: Who was Otto Warburg?\"- Otto Warburg was a German chemist who was the first to study the metabolism of cancer cells.\n","\n"]}],"source":["# do some cleaning of text:\n","# 1. find the last \".\" and delete everything afterwords to have a clean sentense\n","# 2. remove the new line character \\n to make it easier and review\n","# 3. remove <pad> tokens\n","\n","for item, pred in enumerate(predictions):\n","  pred = pred[0:pred.rfind(\".\")+1] # truncate words beyond last period\n","  pred = pred.replace(\"\\n\", \"\") # remove newlines\n","  pred = pred.replace(\"<pad>\", \"\") # remove padding tokens\n","  print(f\"Paragraph {item}: {pred}\\n\")"]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}